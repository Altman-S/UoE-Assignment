{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a26a0a",
   "metadata": {},
   "source": [
    "# Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "964a970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import collections\n",
    "\n",
    "# regular expressions\n",
    "import re\n",
    "# for string.punctuation: list of punctuation characters\n",
    "import string\n",
    "from stemming.porter2 import stem\n",
    "from collections import Counter\n",
    "\n",
    "# import this for storing our BOW format\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "# scikit learn. Contains lots of ML models we can use\n",
    "# import the library for support vector machines\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# from gensim.test.utils import common_texts\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efede719",
   "metadata": {},
   "source": [
    "# 1. IR Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c3c3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read qrels.csv and system_results.csv\n",
    "qrels_mat = np.loadtxt(open(\"qrels.csv\",\"rb\"), delimiter=\",\", skiprows=1)\n",
    "system_results_mat = np.loadtxt(open(\"system_results.csv\",\"rb\"), delimiter=\",\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f755c744",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_number = 6\n",
    "query_number = 10\n",
    "system_number_index = np.array([x[0] for x in system_results_mat])\n",
    "system_query_index = np.array([x[1] for x in system_results_mat])\n",
    "query_id_index = np.array([x[0] for x in qrels_mat])\n",
    "doc_id_index = np.array([x[1] for x in qrels_mat])\n",
    "\n",
    "query_rel_doc = []\n",
    "doc_rel_dict = {}\n",
    "# store relevant doc_id for every query\n",
    "for i in range(query_number):\n",
    "    doc_array = qrels_mat[query_id_index==i+1]\n",
    "    doc_list = [x[1] for x in doc_array]\n",
    "    query_rel_doc.extend([doc_list])\n",
    "    \n",
    "    rel_dict = {}\n",
    "    for j in range(len(doc_array)):\n",
    "        rel_dict[doc_array[j][1]] = doc_array[j][2]\n",
    "    \n",
    "    doc_rel_dict[i+1] = rel_dict\n",
    "\n",
    "# doc_rel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "41176419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {9090.0: 3.0,\n",
       "  6850.0: 2.0,\n",
       "  9574.0: 2.0,\n",
       "  8709.0: 1.0,\n",
       "  9684.0: 1.0,\n",
       "  5011.0: 1.0},\n",
       " 2: {5715.0: 2.0,\n",
       "  9677.0: 2.0,\n",
       "  5766.0: 2.0,\n",
       "  6327.0: 1.0,\n",
       "  6079.0: 1.0,\n",
       "  5653.0: 1.0,\n",
       "  6498.0: 1.0,\n",
       "  7117.0: 1.0},\n",
       " 3: {9743.0: 3.0},\n",
       " 4: {6491.0: 3.0,\n",
       "  5269.0: 3.0,\n",
       "  8032.0: 3.0,\n",
       "  9444.0: 3.0,\n",
       "  8988.0: 2.0,\n",
       "  9445.0: 2.0,\n",
       "  5883.0: 2.0,\n",
       "  7435.0: 2.0,\n",
       "  9745.0: 1.0,\n",
       "  10029.0: 1.0,\n",
       "  7224.0: 1.0,\n",
       "  9038.0: 1.0,\n",
       "  7827.0: 1.0,\n",
       "  6675.0: 1.0,\n",
       "  9720.0: 1.0,\n",
       "  6289.0: 1.0,\n",
       "  9746.0: 1.0,\n",
       "  6836.0: 1.0,\n",
       "  10119.0: 1.0,\n",
       "  4742.0: 1.0,\n",
       "  9739.0: 1.0,\n",
       "  5783.0: 1.0,\n",
       "  10117.0: 1.0,\n",
       "  8414.0: 1.0,\n",
       "  5865.0: 1.0,\n",
       "  8315.0: 1.0,\n",
       "  9523.0: 1.0,\n",
       "  8318.0: 1.0,\n",
       "  6288.0: 1.0,\n",
       "  5268.0: 1.0,\n",
       "  7620.0: 1.0,\n",
       "  7046.0: 1.0,\n",
       "  6054.0: 1.0,\n",
       "  9744.0: 1.0,\n",
       "  6743.0: 1.0,\n",
       "  9278.0: 1.0,\n",
       "  8562.0: 1.0,\n",
       "  6382.0: 1.0,\n",
       "  6334.0: 1.0,\n",
       "  6292.0: 1.0},\n",
       " 5: {1646.0: 1.0,\n",
       "  2126.0: 1.0,\n",
       "  3111.0: 1.0,\n",
       "  4983.0: 1.0,\n",
       "  8646.0: 1.0,\n",
       "  6669.0: 1.0,\n",
       "  8282.0: 1.0},\n",
       " 6: {8433.0: 3.0,\n",
       "  7487.0: 3.0,\n",
       "  6736.0: 3.0,\n",
       "  5305.0: 1.0,\n",
       "  8844.0: 1.0,\n",
       "  9736.0: 1.0,\n",
       "  9541.0: 1.0,\n",
       "  8261.0: 1.0,\n",
       "  8120.0: 1.0,\n",
       "  7424.0: 1.0,\n",
       "  8593.0: 1.0,\n",
       "  7737.0: 1.0},\n",
       " 7: {7646.0: 3.0, 3156.0: 2.0, 4144.0: 1.0},\n",
       " 8: {9891.0: 3.0,\n",
       "  7844.0: 3.0,\n",
       "  9574.0: 2.0,\n",
       "  9684.0: 2.0,\n",
       "  9090.0: 1.0,\n",
       "  9652.0: 1.0,\n",
       "  9281.0: 1.0,\n",
       "  6171.0: 1.0},\n",
       " 9: {5884.0: 3.0,\n",
       "  5995.0: 3.0,\n",
       "  5121.0: 3.0,\n",
       "  6923.0: 3.0,\n",
       "  7686.0: 2.0,\n",
       "  7704.0: 2.0,\n",
       "  6496.0: 2.0,\n",
       "  5565.0: 2.0,\n",
       "  9760.0: 2.0,\n",
       "  8344.0: 2.0,\n",
       "  5138.0: 1.0,\n",
       "  9104.0: 1.0,\n",
       "  7847.0: 1.0,\n",
       "  5644.0: 1.0,\n",
       "  7961.0: 1.0,\n",
       "  7687.0: 1.0,\n",
       "  9647.0: 1.0,\n",
       "  9666.0: 1.0,\n",
       "  7357.0: 1.0,\n",
       "  8186.0: 1.0,\n",
       "  5000.0: 1.0,\n",
       "  7946.0: 1.0,\n",
       "  7825.0: 1.0,\n",
       "  9072.0: 1.0,\n",
       "  8514.0: 1.0,\n",
       "  7690.0: 1.0,\n",
       "  7729.0: 1.0,\n",
       "  7688.0: 1.0,\n",
       "  10019.0: 1.0,\n",
       "  6181.0: 1.0},\n",
       " 10: {7346.0: 3.0, 8840.0: 2.0, 3258.0: 2.0, 5175.0: 1.0, 8566.0: 1.0}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doc_rel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd522bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get P@10 for each system and each query\n",
    "\n",
    "num_traverse = 10\n",
    "p10_list = []\n",
    "# traverse 6 system\n",
    "for i in range(system_number):\n",
    "    # get the array of system for every system 0-6\n",
    "    system_array = system_results_mat[system_number_index==i+1]\n",
    "    query_index = np.array([x[1] for x in system_array])\n",
    "    \n",
    "    p10_query = []\n",
    "    # traverse 10 query\n",
    "    for j in range(query_number):\n",
    "        # get the array of query for every query 0-10\n",
    "        query_array = system_array[query_index==j+1]\n",
    "        query_10 = query_array[:10]\n",
    "        doc_query_10 = [x[2] for x in query_10]\n",
    "       \n",
    "        num_rel = 0\n",
    "        for doc in doc_query_10:\n",
    "            if doc in query_rel_doc[j]:\n",
    "                num_rel += 1\n",
    "                \n",
    "        p10_query.extend([num_rel/num_traverse])\n",
    "            \n",
    "    p10_list.extend([p10_query])\n",
    "\n",
    "# p10_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04a2947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get R@50 for each system and each query\n",
    "\n",
    "r50_list = []\n",
    "# traverse 6 system\n",
    "for i in range(system_number):\n",
    "    # get the array of system for every system 0-6\n",
    "    system_array = system_results_mat[system_number_index==i+1]\n",
    "    query_index = np.array([x[1] for x in system_array])\n",
    "    \n",
    "    r50_query = []\n",
    "    # traverse 10 query\n",
    "    for j in range(query_number):\n",
    "        # get the array of query for every query 0-10\n",
    "        query_array = system_array[query_index==j+1]\n",
    "        query_50 = query_array[:50]\n",
    "        doc_query_50 = [x[2] for x in query_50]\n",
    "       \n",
    "        num_relevant = len(query_rel_doc[j])  # store the num of relevant documents in recall\n",
    "        num_rel = 0\n",
    "        for doc in doc_query_50:\n",
    "            if doc in query_rel_doc[j]:\n",
    "                num_rel += 1\n",
    "                \n",
    "        r50_query.extend([num_rel/num_relevant])\n",
    "            \n",
    "    r50_list.extend([r50_query])\n",
    "\n",
    "# r50_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bbafeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get r-precision for each system and each query\n",
    "\n",
    "rp_list = []\n",
    "# traverse 6 system\n",
    "for i in range(system_number):\n",
    "    # get the array of system for every system 0-6\n",
    "    system_array = system_results_mat[system_number_index==i+1]\n",
    "    query_index = np.array([x[1] for x in system_array])\n",
    "    \n",
    "    rp_query = []\n",
    "    # traverse 10 query\n",
    "    for j in range(query_number):\n",
    "        # get the array of query for every query 0-10\n",
    "        num_relevant = len(query_rel_doc[j])  # store the num of relevant documents in recall\n",
    "    \n",
    "        query_array = system_array[query_index==j+1]\n",
    "        query_n = query_array[:num_relevant]\n",
    "        doc_query_n = [x[2] for x in query_n]\n",
    "       \n",
    "        num_rel = 0\n",
    "        for doc in doc_query_n:\n",
    "            if doc in query_rel_doc[j]:\n",
    "                num_rel += 1\n",
    "                \n",
    "        rp_query.extend([num_rel/num_relevant])\n",
    "            \n",
    "    rp_list.extend([rp_query])\n",
    "\n",
    "# rp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d47714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get AP for each system and each query\n",
    "\n",
    "ap_list = []\n",
    "# traverse 6 system\n",
    "for i in range(system_number):\n",
    "    # get the array of system for every system 0-6\n",
    "    system_array = system_results_mat[system_number_index==i+1]\n",
    "    query_index = np.array([x[1] for x in system_array])\n",
    "    \n",
    "    ap_query = []\n",
    "    # traverse 10 query\n",
    "    for j in range(query_number):\n",
    "        # get the array of query for every query 0-10   \n",
    "        query_array = system_array[query_index==j+1]\n",
    "        doc_query_n = [x[2] for x in query_array]\n",
    "       \n",
    "        ap = 0\n",
    "        rel = 0\n",
    "        traverse = 0\n",
    "        # traverse all documents for each query\n",
    "        for k in range(len(doc_query_n)):\n",
    "            traverse += 1\n",
    "            if doc_query_n[k] in query_rel_doc[j]:\n",
    "                rel += 1\n",
    "                ap += rel / traverse\n",
    "        \n",
    "        ap /= len(query_rel_doc[j])\n",
    "                          \n",
    "        ap_query.extend([ap])\n",
    "            \n",
    "    ap_list.extend([ap_query])\n",
    "\n",
    "# ap_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad2849a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nDCG@10 for each system and each query\n",
    "\n",
    "ndcg10_list = []\n",
    "n = 10\n",
    "ig_lists = []\n",
    "\n",
    "# generate iG list\n",
    "for i in range(query_number):\n",
    "    doc_array = qrels_mat[query_id_index==i+1]\n",
    "    ig_list = [x[2] for x in doc_array]\n",
    "    \n",
    "    if len(ig_list) < n:\n",
    "        for j in range(n-len(ig_list)):\n",
    "            ig_list.extend([0])\n",
    "    else:\n",
    "        ig_list = ig_list[:n]\n",
    "    \n",
    "    ig_lists.extend([ig_list])\n",
    "    \n",
    "# traverse 6 system\n",
    "for i in range(system_number):\n",
    "    # get the array of system for every system 0-6\n",
    "    system_array = system_results_mat[system_number_index==i+1]\n",
    "    query_index = np.array([x[1] for x in system_array])\n",
    "    \n",
    "    ndcg10_query = []\n",
    "    # traverse 10 query\n",
    "    for j in range(query_number):\n",
    "        # get the array of query for every query 0-10   \n",
    "        query_array = system_array[query_index==j+1]\n",
    "        query_n = query_array[:n]\n",
    "        doc_query_n = [x[2] for x in query_n]\n",
    "       \n",
    "        g_list = []\n",
    "        # get G list \n",
    "        for k in range(len(doc_query_n)):\n",
    "            if doc_query_n[k] in query_rel_doc[j]:\n",
    "                g_list.extend([doc_rel_dict[j+1][doc_query_n[k]]])\n",
    "            else:\n",
    "                g_list.extend([0])\n",
    "        \n",
    "        # calculate DCG\n",
    "        dcg = g_list[0]\n",
    "        for p in range(len(g_list)-1):\n",
    "            a = g_list[p + 1] / np.log2(p + 2)\n",
    "            dcg += a\n",
    "            \n",
    "        # calculate iDCG  \n",
    "        ig_list = ig_lists[j]\n",
    "        idcg = ig_list[0]\n",
    "        for q in range(len(ig_list)-1):\n",
    "            b = ig_list[q + 1] / np.log2(q + 2)\n",
    "            idcg += b\n",
    "        \n",
    "        if idcg == 0 :                    \n",
    "            ndcg10_query.extend([0])\n",
    "        else:\n",
    "            ndcg10_query.extend([dcg / idcg])\n",
    "            \n",
    "    ndcg10_list.extend([ndcg10_query])\n",
    "\n",
    "# ndcg10_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eef89fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nDCG@20 for each system and each query\n",
    "\n",
    "ndcg20_list = []\n",
    "n = 20\n",
    "ig_lists = []\n",
    "\n",
    "# generate iG list\n",
    "for i in range(query_number):\n",
    "    doc_array = qrels_mat[query_id_index==i+1]\n",
    "    ig_list = [x[2] for x in doc_array]\n",
    "    \n",
    "    if len(ig_list) < n:\n",
    "        for j in range(n-len(ig_list)):\n",
    "            ig_list.extend([0])\n",
    "    else:\n",
    "        ig_list = ig_list[:n]\n",
    "    \n",
    "    ig_lists.extend([ig_list])\n",
    "    \n",
    "# traverse 6 system\n",
    "for i in range(system_number):\n",
    "    # get the array of system for every system 0-6\n",
    "    system_array = system_results_mat[system_number_index==i+1]\n",
    "    query_index = np.array([x[1] for x in system_array])\n",
    "    \n",
    "    ndcg20_query = []\n",
    "    # traverse 10 query\n",
    "    for j in range(query_number):\n",
    "        # get the array of query for every query 0-10   \n",
    "        query_array = system_array[query_index==j+1]\n",
    "        query_n = query_array[:n]\n",
    "        doc_query_n = [x[2] for x in query_n]\n",
    "       \n",
    "        g_list = []\n",
    "        # get G list \n",
    "        for k in range(len(doc_query_n)):\n",
    "            if doc_query_n[k] in query_rel_doc[j]:\n",
    "                g_list.extend([doc_rel_dict[j+1][doc_query_n[k]]])\n",
    "            else:\n",
    "                g_list.extend([0])\n",
    "        \n",
    "        # calculate DCG\n",
    "        dcg = g_list[0]\n",
    "        for p in range(len(g_list)-1):\n",
    "            a = g_list[p + 1] / np.log2(p + 2)\n",
    "            dcg += a\n",
    "            \n",
    "        # calculate iDCG  \n",
    "        ig_list = ig_lists[j]\n",
    "        idcg = ig_list[0]\n",
    "        for q in range(len(ig_list)-1):\n",
    "            b = ig_list[q + 1] / np.log2(q + 2)\n",
    "            idcg += b\n",
    "        \n",
    "        if idcg == 0 :                    \n",
    "            ndcg20_query.extend([0])\n",
    "        else:\n",
    "            ndcg20_query.extend([dcg / idcg])\n",
    "            \n",
    "    ndcg20_list.extend([ndcg20_query])\n",
    "\n",
    "# ndcg20_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0427e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate p10_mean_list r50_mean_list rp_mean_list ap_mean_list ndcg10_mean_list ndcg20_mean_list\n",
    "\n",
    "p10_mean_list = []; r50_mean_list = []; rp_mean_list = [] \n",
    "ap_mean_list = []; ndcg10_mean_list = []; ndcg20_mean_list = []\n",
    "\n",
    "for i in range(6):\n",
    "    p10_mean_list.extend([np.mean(p10_list[i])])\n",
    "    r50_mean_list.extend([np.mean(r50_list[i])])\n",
    "    rp_mean_list.extend([np.mean(rp_list[i])])\n",
    "    ap_mean_list.extend([np.mean(ap_list[i])])\n",
    "    ndcg10_mean_list.extend([np.mean(ndcg10_list[i])])\n",
    "    ndcg20_mean_list.extend([np.mean(ndcg20_list[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae8310c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.39, 0.22000000000000003, 0.41, 0.08, 0.41, 0.41]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p10_mean_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a824e",
   "metadata": {},
   "source": [
    "### Select the best system (p-value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa003d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p10:  best: 3 second: 6\n",
    "t_p10, p_p10 = scipy.stats.ttest_ind(p10_list[2], p10_list[5])\n",
    "# for r50:  best: 2 second: 1\n",
    "t_r50, p_r50 = scipy.stats.ttest_ind(r50_list[1], r50_list[0])\n",
    "# for r-precision:  best: 3 second: 6\n",
    "t_rp, p_rp = scipy.stats.ttest_ind(rp_list[2], rp_list[5])\n",
    "# for AP:  best: 3 second: 6\n",
    "t_ap, p_ap = scipy.stats.ttest_ind(ap_list[2], ap_list[5])\n",
    "# for nDCG@10:  best: 3 second: 6\n",
    "t_ndcg10, p_ndcg10 = scipy.stats.ttest_ind(ndcg10_list[2], ndcg10_list[5])\n",
    "# for nDCG@20:  best: 3 second: 6\n",
    "t_ndcg20, p_ndcg20 = scipy.stats.ttest_ind(ndcg20_list[2], ndcg20_list[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17507ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic of p10: 0.0   p-value of p10: 1.0\n",
      "t-statistic of r50: 0.3880082704800308   p-value of r50: 0.7025603945402291\n",
      "t-statistic of rp: 0.0   p-value of rp: 1.0\n",
      "t-statistic of ap: 0.042513564801249584   p-value of ap: 0.9665573458870693\n",
      "t-statistic of ndcg10: 0.15065127811699436   p-value of ndcg10: 0.8819262156757446\n",
      "t-statistic of ndcg20: 0.16786186996140187   p-value of ndcg20: 0.8685635746981927\n"
     ]
    }
   ],
   "source": [
    "print('t-statistic of p10: ' + str(t_p10) + '   ' + 'p-value of p10: ' + str(p_p10))\n",
    "print('t-statistic of r50: ' + str(t_r50) + '   ' + 'p-value of r50: ' + str(p_r50))\n",
    "print('t-statistic of rp: ' + str(t_rp) + '   ' + 'p-value of rp: ' + str(p_rp))\n",
    "print('t-statistic of ap: ' + str(t_ap) + '   ' + 'p-value of ap: ' + str(p_ap))\n",
    "print('t-statistic of ndcg10: ' + str(t_ndcg10) + '   ' + 'p-value of ndcg10: ' + str(p_ndcg10))\n",
    "print('t-statistic of ndcg20: ' + str(t_ndcg20) + '   ' + 'p-value of ndcg20: ' + str(p_ndcg20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56af85ad",
   "metadata": {},
   "source": [
    "## Generate ir_eval.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "34d22b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ir_eval.csv', 'w', encoding='utf-8')\n",
    "\n",
    "csv_writer = csv.writer(f)\n",
    "csv_writer.writerow(['system_number', 'query_number', 'P@10', 'R@50', 'r-precision', 'AP', 'nDCG@10', 'nDCG@20'])\n",
    "\n",
    "# traverse 6 systems\n",
    "for i in range(6):\n",
    "    # traverse 10 queries\n",
    "    for j in range(10):\n",
    "        p_10 = round(p10_list[i][j], 3)\n",
    "        r_50 = round(r50_list[i][j], 3)\n",
    "        rp = round(rp_list[i][j], 3)\n",
    "        ap = round(ap_list[i][j], 3)\n",
    "        ndcg10 = round(ndcg10_list[i][j], 3)\n",
    "        ndcg20 = round(ndcg20_list[i][j], 3)\n",
    "        csv_writer.writerow([i+1, j+1, p_10, r_50, rp, ap, ndcg10, ndcg20])\n",
    "    # write mean\n",
    "    p10_mean = round(p10_mean_list[i], 3)\n",
    "    r50_mean = round(r50_mean_list[i], 3)\n",
    "    rp_mean = round(rp_mean_list[i], 3)\n",
    "    ap_mean = round(ap_mean_list[i], 3)\n",
    "    ndcg10_mean = round(ndcg10_mean_list[i], 3)\n",
    "    ndcg20_mean = round(ndcg20_mean_list[i], 3)\n",
    "    csv_writer.writerow([i+1, 'mean', p10_mean, r50_mean, rp_mean, ap_mean, ndcg10_mean, ndcg20_mean])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd026a2a",
   "metadata": {},
   "source": [
    "# 2. Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfa1c84",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05f643c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate OT NT Quran corpus\n",
    "\n",
    "with open('train_and_dev.tsv', 'r') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "data_list = []\n",
    "for d in data:\n",
    "    a = d.rstrip('\\n').split('\\t')\n",
    "    data_list.extend([a])\n",
    "    \n",
    "# get ot_list nt_list quran_list\n",
    "ot_list = []; nt_list = []; quran_list = []\n",
    "for i in range(len(data_list)):\n",
    "    if data_list[i][0] == 'OT':\n",
    "        ot_list.extend([data_list[i][1]])\n",
    "    elif data_list[i][0] == 'NT':\n",
    "        nt_list.extend([data_list[i][1]])\n",
    "    elif data_list[i][0] == 'Quran':\n",
    "        quran_list.extend([data_list[i][1]])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b2b5a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of OT: 20766\n",
      "length of NT: 7112\n",
      "length of Quran: 5616\n"
     ]
    }
   ],
   "source": [
    "print('length of OT: ' + str(len(ot_list)))\n",
    "print('length of NT: ' + str(len(nt_list)))\n",
    "print('length of Quran: ' + str(len(quran_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce326eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete punctuation\n",
    "# re.sub(pattern, repl, string, count=0, flags=0)\n",
    "# put words in englishST into a list\n",
    "with open('englishST.txt', 'r') as eng:\n",
    "    eng_str = eng.read()\n",
    "eng_list = eng_str.split()\n",
    "    \n",
    "r = \"\"\"[0-9!#$%&'\"()*+,-./:;\\\\\\<=>?@[\\]^_`{|}~\\n]\"\"\"\n",
    "\n",
    "def preprocessing(s):\n",
    "    # delete punctuation\n",
    "    no_punct = re.sub(r, ' ', s)\n",
    "\n",
    "    # transform to lower_case\n",
    "    no_punct = no_punct.lower()\n",
    "\n",
    "    # put string to words list\n",
    "    no_list = no_punct.split()\n",
    "\n",
    "    # delete stopping words(englishST.txt) in no_list\n",
    "    stop_list = []\n",
    "    for i in no_list:\n",
    "        if (i not in eng_list):\n",
    "            stop_list.extend([i])\n",
    "\n",
    "    # stemming\n",
    "    norm_list = []\n",
    "    for i in stop_list:\n",
    "        norm_list.append(stem(i))\n",
    "    \n",
    "    return norm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bad47e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 123 ms, total: 12.6 s\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get stemming word_list of OT, NT and Quran corpus\n",
    "# every list in corpus represents a document\n",
    "ot_pre_list = []; nt_pre_list = []; quran_pre_list = []\n",
    "\n",
    "for i in range(len(ot_list)):\n",
    "    line = preprocessing(ot_list[i])\n",
    "    if (len(line) > 0):\n",
    "        ot_pre_list.extend([line])\n",
    "\n",
    "for j in range(len(nt_list)):\n",
    "    line = preprocessing(nt_list[j])\n",
    "    if (len(line) > 0):\n",
    "        nt_pre_list.extend([line])\n",
    "\n",
    "for k in range(len(quran_list)):\n",
    "    line = preprocessing(quran_list[k])\n",
    "    if (len(line) > 0):\n",
    "        quran_pre_list.extend([line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ae36a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of ot_pre_list: 20765\n",
      "length of nt_pre_list: 7100\n",
      "length of quran_pre_list: 5606\n"
     ]
    }
   ],
   "source": [
    "print('length of ot_pre_list: ' + str(len(ot_pre_list)))\n",
    "print('length of nt_pre_list: ' + str(len(nt_pre_list)))\n",
    "print('length of quran_pre_list: ' + str(len(quran_pre_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c90ebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all list\n",
    "ot_all_list = []; nt_all_list = []; quran_all_list = []\n",
    "\n",
    "for i in range(len(ot_pre_list)):\n",
    "    ot_all_list.extend(ot_pre_list[i])\n",
    "for j in range(len(nt_pre_list)):\n",
    "    nt_all_list.extend(nt_pre_list[j])\n",
    "for k in range(len(quran_pre_list)):\n",
    "    quran_all_list.extend(quran_pre_list[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f14519cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get corpus dictionary and its key_list\n",
    "\n",
    "# opeartion for OT\n",
    "ot_counter = Counter(ot_all_list)\n",
    "ot_dict = dict(ot_counter)\n",
    "# operation for NT\n",
    "nt_counter = Counter(nt_all_list)\n",
    "nt_dict = dict(nt_counter)\n",
    "# operation for Quran\n",
    "quran_counter = Counter(quran_all_list)\n",
    "quran_dict = dict(quran_counter)\n",
    "\n",
    "# delete when value < 10\n",
    "list1 = []; list2 = []\n",
    "for key, value in ot_dict.items():\n",
    "    a = 0; b = 0\n",
    "    if key in nt_dict.keys():\n",
    "        a = nt_dict[key]\n",
    "    if key in quran_dict.keys():\n",
    "        b = quran_dict[key]    \n",
    "    if a + b + value >= 10:\n",
    "        list1.append(key)\n",
    "        list2.append(value)\n",
    "         \n",
    "ot_dict = dict(zip(list1,list2))\n",
    "ot_key = list(ot_dict.keys())\n",
    "\n",
    "# delete when value < 10\n",
    "list1 = []; list2 = []\n",
    "for key, value in nt_dict.items():\n",
    "    a = 0; b = 0\n",
    "    if key in ot_dict.keys():\n",
    "        a = ot_dict[key]\n",
    "    if key in quran_dict.keys():\n",
    "        b = quran_dict[key]    \n",
    "    if a + b + value >= 10:\n",
    "        list1.append(key)\n",
    "        list2.append(value)\n",
    "         \n",
    "nt_dict = dict(zip(list1,list2))\n",
    "nt_key = list(nt_dict.keys())\n",
    "\n",
    "# delete when value < 10\n",
    "list1 = []; list2 = []\n",
    "for key, value in quran_dict.items():\n",
    "    a = 0; b = 0\n",
    "    if key in ot_dict.keys():\n",
    "        a = ot_dict[key]\n",
    "    if key in nt_dict.keys():\n",
    "        b = nt_dict[key]    \n",
    "    if a + b + value >= 10:\n",
    "        list1.append(key)\n",
    "        list2.append(value)\n",
    "         \n",
    "quran_dict = dict(zip(list1,list2))\n",
    "quran_key = list(quran_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b73ff78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of ot_key: 2644\n",
      "length of nt_key: 2101\n",
      "length of quran_key: 1771\n",
      "length of special_list: 2823\n"
     ]
    }
   ],
   "source": [
    "# special word list in OT, NT and Quran\n",
    "special_list = list(set(ot_key).union(set(nt_key)).union(set(quran_key)))\n",
    "print('length of ot_key: ' + str(len(ot_key)))\n",
    "print('length of nt_key: ' + str(len(nt_key)))\n",
    "print('length of quran_key: ' + str(len(quran_key)))\n",
    "print('length of special_list: ' + str(len(special_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a55f3c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'israel' in ot_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c15b325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.52 s, sys: 22.9 ms, total: 4.55 s\n",
      "Wall time: 4.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# calculate the number of times every word appears in the document in each corpus\n",
    "\n",
    "# for OT\n",
    "num_ot_dict = {}\n",
    "for i in range(len(ot_key)):\n",
    "    num_ot_dict[ot_key[i]] = 0   \n",
    "for j in range(len(ot_pre_list)):\n",
    "    w_list = list(np.unique(ot_pre_list[j]))\n",
    "    for w in w_list:\n",
    "        if w in ot_key:\n",
    "            num_ot_dict[w] += 1\n",
    "\n",
    "# for NT\n",
    "num_nt_dict = {}\n",
    "for i in range(len(nt_key)):\n",
    "    num_nt_dict[nt_key[i]] = 0   \n",
    "for j in range(len(nt_pre_list)):\n",
    "    w_list = list(np.unique(nt_pre_list[j]))\n",
    "    for w in w_list:\n",
    "        if w in nt_key:\n",
    "            num_nt_dict[w] += 1\n",
    "\n",
    "# for Quran\n",
    "num_quran_dict = {}\n",
    "for i in range(len(quran_key)):\n",
    "    num_quran_dict[quran_key[i]] = 0   \n",
    "for j in range(len(quran_pre_list)):\n",
    "    w_list = list(np.unique(quran_pre_list[j]))\n",
    "    for w in w_list:\n",
    "        if w in quran_key:\n",
    "            num_quran_dict[w] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f6e508",
   "metadata": {},
   "source": [
    "## Compute Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bad5caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mutual information\n",
    "def takeSecond(elem):\n",
    "    return elem[1]\n",
    "\n",
    "N_ot = len(ot_pre_list); N_nt = len(nt_pre_list); N_quran = len(quran_pre_list)\n",
    "N = N_ot + N_nt + N_quran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efd1b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calaculate N N0 N1 N11 N10 N01 N00 for OT\n",
    "\n",
    "mi_ot_list = []; X2_ot_list = []\n",
    "N1 = N_ot  # ot\n",
    "N0 = N - N_ot  # not ot\n",
    "\n",
    "for w in special_list:\n",
    "    N11 = 0\n",
    "    if w in ot_key:  # in ot\n",
    "        N11 = num_ot_dict[w]          \n",
    "    N01 = N1 - N11\n",
    "       \n",
    "    N10 = 0\n",
    "    if w in nt_key:  # in nt\n",
    "        N10 += num_nt_dict[w] \n",
    "    if w in quran_key:  # in quran\n",
    "        N10 += num_quran_dict[w]     \n",
    "    N00 = N0 - N10\n",
    "    \n",
    "    a = 0; b = 0; c = 0; d = 0\n",
    "    if N11 != 0:\n",
    "        a = (N11 / N) * np.log2((N * N11)/((N10+N11) * N1))\n",
    "    if N01 != 0:\n",
    "        b = (N01 / N) * np.log2((N * N01)/((N00+N01) * N1))\n",
    "    if N10 != 0:\n",
    "        c = (N10 / N) * np.log2((N * N10)/((N10+N11) * N0))\n",
    "    if N00 != 0:\n",
    "        d = (N00 / N) * np.log2((N * N00)/((N00+N01) * N0))\n",
    "       \n",
    "    mi = a + b + c + d\n",
    "    X2 = ((N11+N10+N01+N00)*(N11*N00-N10*N01)**2) / ((N11+N01)*(N11+N10)*(N10+N00)*(N01+N00))\n",
    "     \n",
    "    mi_ot_list.extend([[w, mi]])\n",
    "    X2_ot_list.extend([[w, X2]])\n",
    "    \n",
    "mi_ot_list.sort(key=takeSecond, reverse=True)\n",
    "X2_ot_list.sort(key=takeSecond, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29516d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calaculate N N0 N1 N11 N10 N01 N00 for NT\n",
    "\n",
    "mi_nt_list = []; X2_nt_list = []\n",
    "N1 = N_nt  # nt\n",
    "N0 = N - N_nt  # not nt\n",
    "\n",
    "for w in special_list:\n",
    "    N11 = 0\n",
    "    if w in nt_key:  # in nt\n",
    "        N11 = num_nt_dict[w]          \n",
    "    N01 = N1 - N11\n",
    "       \n",
    "    N10 = 0\n",
    "    if w in ot_key:  # in ot\n",
    "        N10 += num_ot_dict[w] \n",
    "    if w in quran_key:  # in quran\n",
    "        N10 += num_quran_dict[w]     \n",
    "    N00 = N0 - N10\n",
    "    \n",
    "    a = 0; b = 0; c = 0; d = 0\n",
    "    if N11 != 0:\n",
    "        a = (N11 / N) * np.log2((N * N11)/((N10+N11) * N1))\n",
    "    if N01 != 0:\n",
    "        b = (N01 / N) * np.log2((N * N01)/((N00+N01) * N1))\n",
    "    if N10 != 0:\n",
    "        c = (N10 / N) * np.log2((N * N10)/((N10+N11) * N0))\n",
    "    if N00 != 0:\n",
    "        d = (N00 / N) * np.log2((N * N00)/((N00+N01) * N0))\n",
    "       \n",
    "    mi = a + b + c + d\n",
    "    X2 = ((N11+N10+N01+N00)*(N11*N00-N10*N01)**2) / ((N11+N01)*(N11+N10)*(N10+N00)*(N01+N00))\n",
    "     \n",
    "    mi_nt_list.extend([[w, mi]])\n",
    "    X2_nt_list.extend([[w, X2]])\n",
    "    \n",
    "mi_nt_list.sort(key=takeSecond, reverse=True)\n",
    "X2_nt_list.sort(key=takeSecond, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58d88001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calaculate N N0 N1 N11 N10 N01 N00 for Quran\n",
    "\n",
    "mi_quran_list = []; X2_quran_list = []\n",
    "N1 = N_quran  # quran\n",
    "N0 = N - N_quran  # not quran\n",
    "\n",
    "for w in special_list:\n",
    "    N11 = 0\n",
    "    if w in quran_key:  # in quran\n",
    "        N11 = num_quran_dict[w]          \n",
    "    N01 = N1 - N11\n",
    "       \n",
    "    N10 = 0\n",
    "    if w in ot_key:  # in ot\n",
    "        N10 += num_ot_dict[w] \n",
    "    if w in nt_key:  # in nt\n",
    "        N10 += num_nt_dict[w]     \n",
    "    N00 = N0 - N10\n",
    "    \n",
    "    a = 0; b = 0; c = 0; d = 0\n",
    "    if N11 != 0:\n",
    "        a = (N11 / N) * np.log2((N * N11)/((N10+N11) * N1))\n",
    "    if N01 != 0:\n",
    "        b = (N01 / N) * np.log2((N * N01)/((N00+N01) * N1))\n",
    "    if N10 != 0:\n",
    "        c = (N10 / N) * np.log2((N * N10)/((N10+N11) * N0))\n",
    "    if N00 != 0:\n",
    "        d = (N00 / N) * np.log2((N * N00)/((N00+N01) * N0))\n",
    "       \n",
    "    mi = a + b + c + d\n",
    "    X2 = ((N11+N10+N01+N00)*(N11*N00-N10*N01)**2) / ((N11+N01)*(N11+N10)*(N10+N00)*(N01+N00))\n",
    "     \n",
    "    mi_quran_list.extend([[w, mi]])\n",
    "    X2_quran_list.extend([[w, X2]])\n",
    "    \n",
    "mi_quran_list.sort(key=takeSecond, reverse=True)\n",
    "X2_quran_list.sort(key=takeSecond, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c67926",
   "metadata": {},
   "source": [
    "## Output MI and X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "296b6cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['god', 0.03153127928829265],\n",
       " ['muhammad', 0.028866958854356823],\n",
       " ['believ', 0.019710986535567396],\n",
       " ['torment', 0.019665532570955824],\n",
       " ['messeng', 0.015592852710699903],\n",
       " ['revel', 0.01390536208881128],\n",
       " ['king', 0.013097948078937837],\n",
       " ['israel', 0.013023790650338828],\n",
       " ['unbeliev', 0.012542024266425358],\n",
       " ['guidanc', 0.012242290887039623]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_quran_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea98b04",
   "metadata": {},
   "source": [
    "## TOPIC-LEVEL COMPARISONS (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbbf20b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.08 s, sys: 34.5 ms, total: 7.11 s\n",
      "Wall time: 7.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a corpus from a list of texts\n",
    "common_texts = ot_pre_list.copy()\n",
    "common_texts.extend(nt_pre_list)\n",
    "common_texts.extend(quran_pre_list)\n",
    "\n",
    "common_dictionary = Dictionary(common_texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in common_texts]\n",
    "\n",
    "# Train the model on the corpus\n",
    "lda = LdaModel(common_corpus, num_topics=20, id2word=common_dictionary, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7022b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfec4885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get topic score for ot_pre_list:\n",
    "ot_score_list = []\n",
    "for i in range(len(ot_pre_list)):\n",
    "    doc = ot_pre_list[i]\n",
    "    doc_bow = common_dictionary.doc2bow(doc)\n",
    "    ot_score_list.extend([lda.get_document_topics(doc_bow, minimum_probability=0)])\n",
    "\n",
    "# get topic score for nt_pre_list:\n",
    "nt_score_list = []\n",
    "for j in range(len(nt_pre_list)):\n",
    "    doc = nt_pre_list[j]\n",
    "    doc_bow = common_dictionary.doc2bow(doc)\n",
    "    nt_score_list.extend([lda.get_document_topics(doc_bow, minimum_probability=0)])\n",
    "\n",
    "# get topic score for quran_pre_list:\n",
    "quran_score_list = []\n",
    "for k in range(len(quran_pre_list)):\n",
    "    doc = quran_pre_list[k]\n",
    "    doc_bow = common_dictionary.doc2bow(doc)\n",
    "    quran_score_list.extend([lda.get_document_topics(doc_bow, minimum_probability=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7dca503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get topic average score for ot_pre_list, nt_avg_list and quran_avg_list\n",
    "num_topic = 20\n",
    "ot_avg_list = []; nt_avg_list = []; quran_avg_list = [] \n",
    "\n",
    "for i in range(num_topic):\n",
    "    # for ot_avg_list\n",
    "    ot_score = [x[i][1] for x in ot_score_list]\n",
    "    ot_avg_score = sum(ot_score) / len(ot_score)\n",
    "    ot_avg_list.extend([(i, ot_avg_score)])\n",
    "    # for nt_avg_list\n",
    "    nt_score = [x[i][1] for x in nt_score_list]\n",
    "    nt_avg_score = sum(nt_score) / len(nt_score)\n",
    "    nt_avg_list.extend([(i, nt_avg_score)])\n",
    "    # for quran_avg_list\n",
    "    quran_score = [x[i][1] for x in quran_score_list]\n",
    "    quran_avg_score = sum(quran_score) / len(quran_score)\n",
    "    quran_avg_list.extend([(i, quran_avg_score)])\n",
    "    \n",
    "ot_avg_list.sort(key=takeSecond, reverse=True)\n",
    "nt_avg_list.sort(key=takeSecond, reverse=True)\n",
    "quran_avg_list.sort(key=takeSecond, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f38c0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 topics in OT: [(18, 0.07698535544350618), (11, 0.06747042924715593), (12, 0.05813475964167517)]\n",
      "Top 3 topics in NT: [(13, 0.08209313911064463), (16, 0.06848463969026417), (18, 0.06589683862737525)]\n",
      "Top 3 topics in Quran: [(11, 0.1269977275438763), (18, 0.09698604104876876), (13, 0.09211305664083747)]\n"
     ]
    }
   ],
   "source": [
    "print('Top 3 topics in OT: ' + str(ot_avg_list[:3]))\n",
    "print('Top 3 topics in NT: ' + str(nt_avg_list[:3]))\n",
    "print('Top 3 topics in Quran: ' + str(quran_avg_list[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86824033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.253*\"god\" + 0.062*\"lord\" + 0.052*\"judgment\" + 0.037*\"peopl\" + 0.029*\"evil\" + 0.023*\"children\" + 0.021*\"day\" + 0.020*\"abraham\" + 0.019*\"glori\" + 0.018*\"afraid\"\n",
      "0.101*\"god\" + 0.074*\"lord\" + 0.061*\"peopl\" + 0.047*\"truth\" + 0.041*\"deed\" + 0.036*\"book\" + 0.035*\"forgiv\" + 0.033*\"turn\" + 0.032*\"great\" + 0.028*\"merci\"\n",
      "0.161*\"messeng\" + 0.149*\"son\" + 0.083*\"spirit\" + 0.080*\"prophet\" + 0.024*\"testifi\" + 0.023*\"wait\" + 0.022*\"wife\" + 0.019*\"man\" + 0.018*\"name\" + 0.017*\"daughter\"\n"
     ]
    }
   ],
   "source": [
    "print(lda.print_topic(18))\n",
    "print(lda.print_topic(11))\n",
    "print(lda.print_topic(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66d38d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20765\n",
      "7100\n",
      "5606\n"
     ]
    }
   ],
   "source": [
    "print(len(ot_pre_list))\n",
    "print(len(nt_pre_list))\n",
    "print(len(quran_pre_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab91534",
   "metadata": {},
   "source": [
    "# 3. Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "029380c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##########################################\n",
    "# # stemming + stopping\n",
    "# # Shuffle the order of data\n",
    "# all_X = ot_pre_list.copy()\n",
    "# all_X.extend(nt_pre_list)\n",
    "# all_X.extend(quran_pre_list)\n",
    "\n",
    "# all_y = []\n",
    "# for i in range(len(ot_pre_list)):\n",
    "#     all_y.extend(['ot'])\n",
    "# for j in range(len(nt_pre_list)):\n",
    "#     all_y.extend(['nt'])\n",
    "# for k in range(len(quran_pre_list)):\n",
    "#     all_y.extend(['quran'])\n",
    "\n",
    "# # Split the dataset into training set and a seperate development set\n",
    "# X_training, X_deving, y_training, y_deving = train_test_split(all_X, all_y, train_size=0.9, test_size=0.1, shuffle=True)\n",
    "\n",
    "# # get vocab set\n",
    "# vocab_set = set([])\n",
    "\n",
    "# for doc1 in ot_pre_list:\n",
    "#     for word1 in doc1:\n",
    "#         vocab_set.add(word1)\n",
    "# for doc2 in nt_pre_list:\n",
    "#     for word2 in doc2:\n",
    "#         vocab_set.add(word2)\n",
    "# for doc3 in quran_pre_list:\n",
    "#     for word3 in doc3:\n",
    "#         vocab_set.add(word3)\n",
    "# ##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14d8cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenisation\n",
    "r = \"\"\"[0-9!#$%&'\"()*+,-./:;\\\\\\<=>?@[\\]^_`{|}~\\n]\"\"\"\n",
    "\n",
    "def tokenising(s):\n",
    "    # delete punctuation\n",
    "    no_punct = re.sub(r, ' ', s)\n",
    "\n",
    "    # transform to lower_case\n",
    "    no_punct = no_punct.lower()\n",
    "\n",
    "    # put string to words list\n",
    "    no_list = no_punct.split()\n",
    "    \n",
    "    return no_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0eb6f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 239 ms, sys: 34.8 ms, total: 274 ms\n",
      "Wall time: 308 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get tokenising word_list of OT, NT and Quran corpus\n",
    "# every list in corpus represents a document\n",
    "ot_token_list = []; nt_token_list = []; quran_token_list = []\n",
    "\n",
    "for i in range(len(ot_list)):\n",
    "    line = tokenising(ot_list[i])\n",
    "    if (len(line) > 0):\n",
    "        ot_token_list.extend([line])\n",
    "\n",
    "for j in range(len(nt_list)):\n",
    "    line = tokenising(nt_list[j])\n",
    "    if (len(line) > 0):\n",
    "        nt_token_list.extend([line])\n",
    "\n",
    "for k in range(len(quran_list)):\n",
    "    line = tokenising(quran_list[k])\n",
    "    if (len(line) > 0):\n",
    "        quran_token_list.extend([line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "262f5746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of ot_token_list: 20766\n",
      "length of nt_token_list: 7112\n",
      "length of quran_token_list: 5616\n"
     ]
    }
   ],
   "source": [
    "print('length of ot_token_list: ' + str(len(ot_token_list)))\n",
    "print('length of nt_token_list: ' + str(len(nt_token_list)))\n",
    "print('length of quran_token_list: ' + str(len(quran_token_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a57f9bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocab set\n",
    "vocab_set = set([])\n",
    "\n",
    "for doc1 in ot_token_list:\n",
    "    for word1 in doc1:\n",
    "        vocab_set.add(word1)\n",
    "for doc2 in nt_token_list:\n",
    "    for word2 in doc2:\n",
    "        vocab_set.add(word2)\n",
    "for doc3 in quran_token_list:\n",
    "    for word3 in doc3:\n",
    "        vocab_set.add(word3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "384153e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the order of data\n",
    "all_X = ot_token_list.copy()\n",
    "all_X.extend(nt_token_list)\n",
    "all_X.extend(quran_token_list)\n",
    "\n",
    "all_y = []\n",
    "for i in range(len(ot_token_list)):\n",
    "    all_y.extend(['ot'])\n",
    "for j in range(len(nt_token_list)):\n",
    "    all_y.extend(['nt'])\n",
    "for k in range(len(quran_token_list)):\n",
    "    all_y.extend(['quran'])\n",
    "\n",
    "# Split the dataset into training set and a seperate development set\n",
    "X_training, X_deving, y_training, y_deving = train_test_split(all_X, all_y, train_size=0.9, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816abc8d",
   "metadata": {},
   "source": [
    "### Process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c9ef116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################################################\n",
    "# # stemming + stopping\n",
    "# with open('test.tsv', 'r') as f:\n",
    "#     test = f.readlines()\n",
    "\n",
    "# test_list = []\n",
    "# for d in test:\n",
    "#     a = d.rstrip('\\n').split('\\t')\n",
    "#     test_list.extend([a])\n",
    "    \n",
    "# # get X_testing and y_testing\n",
    "# X_testing = []; y_testing = []\n",
    "# for i in range(len(test_list)):\n",
    "#     line = preprocessing(test_list[i][1])\n",
    "#     if len(line) > 0:\n",
    "#         X_testing.extend([line])\n",
    "#         y_testing.extend([test_list[i][0].lower()])\n",
    "# ########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0669331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99b141d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test.tsv file\n",
    "with open('test.tsv', 'r') as f:\n",
    "    test = f.readlines()\n",
    "\n",
    "test_list = []\n",
    "for d in test:\n",
    "    a = d.rstrip('\\n').split('\\t')\n",
    "    test_list.extend([a])\n",
    "    \n",
    "# get doc_list and label_list\n",
    "doc_list = []; label_list = []\n",
    "for i in range(len(test_list)):\n",
    "    doc_list.extend([test_list[i][1]])\n",
    "    label_list.extend([test_list[i][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "869a8fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenise doc_list and get X_testing and y_testing\n",
    "X_testing = []; y_testing = []\n",
    "for i in range(len(doc_list)):\n",
    "    line = tokenising(doc_list[i])\n",
    "    if (len(line) > 0):\n",
    "        X_testing.extend([line])\n",
    "        y_testing.extend([label_list[i].lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "473b74a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3843"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcb8a91",
   "metadata": {},
   "source": [
    "### Set up mappings for word and category IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4b86057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word id for dog is 11046\n",
      "The category id for nt is 0\n"
     ]
    }
   ],
   "source": [
    "# convert the vocab to a word id lookup dictionary\n",
    "# anything not in this will be considered \"out of vocabulary\" OOV\n",
    "word2id = {}\n",
    "for word_id,word in enumerate(vocab_set):\n",
    "    word2id[word] = word_id\n",
    "    \n",
    "# and do the same for the categories\n",
    "categories = ['ot', 'nt', 'quran']\n",
    "cat2id = {}\n",
    "for cat_id,cat in enumerate(set(categories)):\n",
    "    cat2id[cat] = cat_id\n",
    "    \n",
    "print(\"The word id for dog is\",word2id['dog'])\n",
    "print(\"The category id for nt is\",cat2id['nt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb2e584",
   "metadata": {},
   "source": [
    "### Convert data to bag-of-words format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b11f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a BOW representation of the files: use the scipy \n",
    "# data is the preprocessed_data\n",
    "# word2id maps words to their ids\n",
    "def convert_to_bow_matrix(preprocessed_data, word2id):\n",
    "    \n",
    "    # matrix size is number of docs x vocab size + 1 (for OOV)\n",
    "    matrix_size = (len(preprocessed_data),len(word2id)+1)\n",
    "    oov_index = len(word2id)\n",
    "    # matrix indexed by [doc_id, token_id]\n",
    "    X = scipy.sparse.dok_matrix(matrix_size)\n",
    "\n",
    "    # iterate through all documents in the dataset\n",
    "    for doc_id,doc in enumerate(preprocessed_data):\n",
    "        for word in doc:\n",
    "            # default is 0, so just add to the count for this word in this doc\n",
    "            # if the word is oov, increment the oov_index\n",
    "            X[doc_id,word2id.get(word,oov_index)] += 1\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a2a7cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.7 s, sys: 184 ms, total: 21.9 s\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# generate X_train\n",
    "X_train = convert_to_bow_matrix(X_training, word2id)\n",
    "# generate y_train\n",
    "y_train = [cat2id[cat] for cat in y_training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74dea473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check some docs\n",
    "# print(\"First 3 documents in X_train are:\",X_train[:3])\n",
    "# print(\"First 3 documents in y_train are:\",y_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af99185",
   "metadata": {},
   "source": [
    "### Train an SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6b6aec29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 s, sys: 166 ms, total: 12.2 s\n",
      "Wall time: 12.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1000, max_iter=5000)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = sklearn.svm.LinearSVC(C=1000, max_iter=5000)\n",
    "# model = sklearn.svm.SVC(C=1000)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa37179",
   "metadata": {},
   "source": [
    "### Evaluating the model (using train set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "005fd6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999336518046709\n"
     ]
    }
   ],
   "source": [
    "# evaluate on training data: how well did we fit to the data we trained on?\n",
    "y_train_predictions = model.predict(X_train)\n",
    "\n",
    "# now can compute any metrics we care about. Let's quickly do accuracy\n",
    "def compute_accuracy(predictions, true_values):\n",
    "    num_correct = 0\n",
    "    num_total = len(predictions)\n",
    "    for predicted,true in zip(predictions, true_values):\n",
    "        if predicted==true:\n",
    "            num_correct += 1\n",
    "    return num_correct / num_total\n",
    "\n",
    "accuracy = compute_accuracy(y_train_predictions, y_train)\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a83cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = []\n",
    "for cat,cid in sorted(cat2id.items(),key=lambda x:x[1]):\n",
    "    cat_names.append(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4cb72c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          nt      1.000     1.000     1.000      6421\n",
      "          ot      1.000     1.000     1.000     18645\n",
      "       quran      1.000     1.000     1.000      5078\n",
      "\n",
      "    accuracy                          1.000     30144\n",
      "   macro avg      1.000     1.000     1.000     30144\n",
      "weighted avg      1.000     1.000     1.000     30144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute the precision, recall and f1-score for train\n",
    "print(classification_report(y_train, y_train_predictions, target_names=cat_names, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d29d51",
   "metadata": {},
   "source": [
    "### Using dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "11d13960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_abc_accuracy(predictions, true_values):\n",
    "    num_correct = 0\n",
    "    error_num = 0\n",
    "    num_total = len(predictions)\n",
    "    for predicted,true in zip(predictions, true_values):\n",
    "        if predicted==true:\n",
    "            num_correct += 1\n",
    "        else:\n",
    "            print(error_num)\n",
    "        error_num += 1\n",
    "        \n",
    "    return num_correct / num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "093032b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8588059701492538\n"
     ]
    }
   ],
   "source": [
    "# prepare dev data in the same was as training data\n",
    "X_dev = convert_to_bow_matrix(X_deving, word2id)\n",
    "y_dev = [cat2id[cat] for cat in y_deving]\n",
    "\n",
    "y_dev_predictions = model.predict(X_dev)\n",
    "accuracy = compute_accuracy(y_dev_predictions, y_dev)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "178089ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          nt      0.878     0.825     0.851       691\n",
      "          ot      0.934     0.960     0.947      2121\n",
      "       quran      0.933     0.903     0.918       538\n",
      "\n",
      "    accuracy                          0.923      3350\n",
      "   macro avg      0.915     0.896     0.905      3350\n",
      "weighted avg      0.922     0.923     0.922      3350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute the precision, recall and f1-score for dev\n",
    "print(classification_report(y_dev, y_dev_predictions, target_names=cat_names, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15262bef",
   "metadata": {},
   "source": [
    "### Using test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb2f5372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9175123601353109\n"
     ]
    }
   ],
   "source": [
    "# prepare dev data in the same was as training data\n",
    "X_test = convert_to_bow_matrix(X_testing, word2id)\n",
    "y_test = [cat2id[cat] for cat in y_testing]\n",
    "\n",
    "y_test_predictions = model.predict(X_test)\n",
    "accuracy = compute_accuracy(y_test_predictions, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b2666cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          nt      0.881     0.832     0.856       844\n",
      "          ot      0.928     0.953     0.940      2379\n",
      "       quran      0.924     0.900     0.912       620\n",
      "\n",
      "    accuracy                          0.918      3843\n",
      "   macro avg      0.911     0.895     0.902      3843\n",
      "weighted avg      0.917     0.918     0.917      3843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute the precision, recall and f1-score for dev\n",
    "print(classification_report(y_test, y_test_predictions, target_names=cat_names, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7c5125",
   "metadata": {},
   "source": [
    "## Improved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1997272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate df dictionary\n",
    "N = len(X_training)\n",
    "df_dict = {}\n",
    "for w in vocab_set:\n",
    "    df_dict[w] = 0\n",
    "df_set = set(df_dict.keys())\n",
    "\n",
    "for i in range(len(X_training)):\n",
    "    words = set(X_training[i])\n",
    "    for word in words:\n",
    "        if word in df_set:\n",
    "            df_dict[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e857d72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tfidf_matrix(preprocessed_data, word2id):\n",
    "    \n",
    "    # matrix size is number of docs x vocab size + 1 (for OOV)\n",
    "    matrix_size = (len(preprocessed_data),len(word2id))\n",
    "\n",
    "    # matrix indexed by [doc_id, token_id]\n",
    "    X = scipy.sparse.dok_matrix(matrix_size)\n",
    "\n",
    "    # iterate through all documents in the dataset\n",
    "    for doc_id,doc in enumerate(preprocessed_data):\n",
    "        for word in doc:\n",
    "            # default is 0, so just add to the count for this word in this doc\n",
    "            if word in df_set:\n",
    "                X[doc_id, word2id.get(word)] += 1\n",
    "        for word in doc:\n",
    "            if word in df_set:\n",
    "                a = (1 + np.log10(X[doc_id, word2id.get(word)])) * np.log10(N / df_dict[word])\n",
    "                X[doc_id, word2id.get(word)] = a\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5621184c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 251 ms, sys: 9.64 ms, total: 260 ms\n",
      "Wall time: 274 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# # generate X_train_improved\n",
    "# X_train_improved = convert_to_tfidf_matrix(X_training, word2id)\n",
    "# # generate y_train_improved\n",
    "# y_train_improved = [cat2id[cat] for cat in y_training]\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train)\n",
    "X_train_improved = tf_transformer.transform(X_train)\n",
    "y_train_improved = [cat2id[cat] for cat in y_training]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e304f902",
   "metadata": {},
   "source": [
    "### Train a SVM Model (improved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fd6347b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 s, sys: 49.8 ms, total: 12.7 s\n",
      "Wall time: 12.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1000, max_iter=5000)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "improved_model = sklearn.svm.LinearSVC(C=1000, max_iter=5000)\n",
    "improved_model.fit(X_train_improved, y_train_improved)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8ba31b",
   "metadata": {},
   "source": [
    "### Evaluating the improved Model (using train set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f6a67945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9965167197452229\n"
     ]
    }
   ],
   "source": [
    "# evaluate on training data: how well did we fit to the data we trained on?\n",
    "y_train_improved_predictions = improved_model.predict(X_train_improved)\n",
    "accuracy = compute_accuracy(y_train_improved_predictions, y_train_improved)\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cc51c997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ot      0.997     0.998     0.997     18695\n",
      "          nt      0.993     0.991     0.992      6372\n",
      "       quran      1.000     0.999     1.000      5077\n",
      "\n",
      "    accuracy                          0.997     30144\n",
      "   macro avg      0.997     0.996     0.996     30144\n",
      "weighted avg      0.997     0.997     0.997     30144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute the precision, recall and f1-score for train\n",
    "print(classification_report(y_train_improved, y_train_improved_predictions, target_names=cat_names, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088d876b",
   "metadata": {},
   "source": [
    "### Using dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5bad7945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8722388059701492\n"
     ]
    }
   ],
   "source": [
    "# prepare dev data in the same was as training data\n",
    "tf_transformer2 = TfidfTransformer(use_idf=False).fit(X_dev)\n",
    "X_dev_improved = tf_transformer2.transform(X_dev)\n",
    "y_dev_improved = [cat2id[cat] for cat in y_deving]\n",
    "# X_dev_improved = convert_to_tfidf_matrix(X_deving, word2id)\n",
    "# y_dev_improved = [cat2id[cat] for cat in y_deving]\n",
    "\n",
    "y_dev_improved_predictions = improved_model.predict(X_dev_improved)\n",
    "accuracy = compute_accuracy(y_dev_improved_predictions, y_dev_improved)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "178e61c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ot      0.920     0.902     0.911      2071\n",
      "          nt      0.757     0.793     0.775       740\n",
      "       quran      0.858     0.865     0.861       539\n",
      "\n",
      "    accuracy                          0.872      3350\n",
      "   macro avg      0.845     0.853     0.849      3350\n",
      "weighted avg      0.874     0.872     0.873      3350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute the precision, recall and f1-score for dev\n",
    "print(classification_report(y_dev_improved, y_dev_improved_predictions, target_names=cat_names, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c4faa9",
   "metadata": {},
   "source": [
    "### Using test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ca6650b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.882903981264637\n"
     ]
    }
   ],
   "source": [
    "# prepare dev data in the same was as training data\n",
    "tf_transformer3 = TfidfTransformer(use_idf=False).fit(X_test)\n",
    "X_test_improved = tf_transformer2.transform(X_test)\n",
    "y_test_improved = [cat2id[cat] for cat in y_testing]\n",
    "\n",
    "y_test_improved_predictions = improved_model.predict(X_test_improved)\n",
    "accuracy = compute_accuracy(y_test_improved_predictions, y_test_improved)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bebea0b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_improved' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hc/nb68sdy94m18z5wflv2b1v2c0000gn/T/ipykernel_1669/3768965390.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# compute the precision, recall and f1-score for dev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_improved\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_improved_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test_improved' is not defined"
     ]
    }
   ],
   "source": [
    "# compute the precision, recall and f1-score for dev\n",
    "print(classification_report(y_test_improved, y_test_improved_predictions, target_names=cat_names, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a24eaf0",
   "metadata": {},
   "source": [
    "# Output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "59e460b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('classification.csv', 'w', encoding='utf-8')\n",
    "\n",
    "csv_writer = csv.writer(f)\n",
    "csv_writer.writerow(['system', 'split', 'p-quran', 'r-quran', 'f-quran', 'p-ot', 'r-ot', 'f-ot', 'p-nt', 'r-nt', 'f-nt', 'p-macro', 'r-macro', 'f-macro'])\n",
    "\n",
    "csv_writer.writerow(['baseline', 'train', 0.998, 0.994, 0.996, 0.997, 0.991, 0.994, 0.972, 0.993, 0.982, 0.989, 0.992, 0.991])\n",
    "csv_writer.writerow(['baseline', 'dev', 0.826, 0.852, 0.838, 0.917, 0.874, 0.895, 0.714, 0.792, 0.751, 0.819, 0.839, 0.828])\n",
    "csv_writer.writerow(['baseline', 'test', 0.843, 0.831, 0.837, 0.921, 0.888, 0.904, 0.744, 0.827, 0.783, 0.836, 0.848, 0.841])\n",
    "\n",
    "csv_writer.writerow(['improved', 'train', 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000])\n",
    "csv_writer.writerow(['improved', 'dev', 0.933, 0.903, 0.918, 0.878, 0.825, 0.851, 0.934, 0.960, 0.947, 0.915, 0.896, 0.905])\n",
    "csv_writer.writerow(['improved', 'test', 0.924, 0.900, 0.912, 0.881, 0.832, 0.856, 0.928, 0.953, 0.940, 0.911, 0.895, 0.902])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0091a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d401d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cad207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6fca47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c5c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735e9b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c19514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make a prediction\n",
    "# n = 2\n",
    "# sample_text = X_deving[n]\n",
    "# # create just a single vector as input (as a 1 x V matrix)\n",
    "# sample_x_in = scipy.sparse.dok_matrix((1,len(word2id)+1))\n",
    "# for word in sample_text:\n",
    "#     sample_x_in[0,word2id[word]] += 1\n",
    "\n",
    "# # what does the example document look like?\n",
    "# print(sample_x_in)\n",
    "# prediction = model.predict(sample_x_in)\n",
    "# # what category was predicted?\n",
    "# print(\"Prediction was:\", prediction[0])\n",
    "# # what category was that?\n",
    "# print(cat2id)\n",
    "# # what category in real?\n",
    "# print(\"Real was:\", y_deving[n])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
